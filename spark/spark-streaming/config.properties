#------------------etl-streaming-preprocess job配置----------------------

# 连接池配置(默认不需修改)
## 连接池启动时创建的初始化连接数量（默认值为0）
executor.pool.initialSize=2
## 连接池中可同时连接的最大的连接数（默认值为8，自己根据应用场景定）
executor.pool.maxActive=10
## 连接池中最大的空闲的连接数，超过的空闲连接将被释放，如果设置为负数表示不限制（默认为8个)
executor.pool.maxIdle=5
## 最小空闲连接
executor.pool.minIdle=2
## 最大等待时间，当没有可用连接时，连接池等待连接释放的最大时间，超过该时间限制会抛出异常，如果设置-1表示无限等待（默认为无限，调整为60000ms，避免因线程池不够用，而导致请求被无限制挂起）
executor.pool.maxWait=60000
## 验证连接是否可用，使用的SQL语句
executor.pool.validationQuery=SELECT 1
## 指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除
executor.pool.testWhileIdle=true
## 借出连接时不要测试，否则很影响性能
executor.pool.testOnBorrow=false
## 每30秒运行一次空闲连接回收器
executor.pool.timeBetweenEvictionRunsMillis=30000
## 池中的连接空闲30分钟后被回收,默认值就是30分钟。
executor.pool.minEvictableIdleTimeMillis=1800000
## 在每次空闲连接回收器线程(如果有)运行时检查的连接数量，默认值就是3.
executor.pool.numTestsPerEvictionRun=1
## JDBC驱动建立连接时附带的连接属性属性的格式必须为这样：[属性名=property;]
## 注意："user" 与 "password" 两个属性会被明确地传递，因此这里不需要包含他们。
executor.pool.connectionProperties=useUnicode=true;characterEncoding=utf8

#########  主要修改下述配置  #########

streaming.app.name=StreamingPreProcess
streaming.app.close.port=19999

zookeeper.servers=192.168.11.130:2181

## db 配置
### dwd db
dwd.url=jdbc:pivotal:greenplum://192.168.11.72:5432;DatabaseName=bigdata_dwd
dwd.driver=com.pivotal.jdbc.GreenplumDriver
dwd.user=gpadmin
dwd.passwd=gpadmin
dwd.batchsize=2000
dwd.table=public.dwd_bigdata_event_face_5029

## 引擎质量属性建档阈值，大于这个阈值才可用于建档
preProcess.clusterQualityThreshold=0.79
## 引擎质量属性归档阈值，大于这个阈值才可用于归档
preProcess.classQualityThreshold=0.30
## 角度阈值
preProcess.clusterPitchThreshold=14
preProcess.clusterRollThreshold=14
preProcess.clusterYawThreshold=14
preProcess.classPitchThreshold=59
preProcess.classRollThreshold=49
preProcess.classYawThreshold=43

## producer
kafka.bootstrap.servers=192.168.11.130:9092
kafka.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.value.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.acks=all
kafka.retries=3
kafka.batch.size=20684
kafka.buffer.memory=33554432
kafka.linger.ms=1

## consumer
kafka.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.receive.buffer.bytes=102400
kafka.max.partition.fetch.bytes=5252880
kafka.auto.offset.reset=earliest
kafka.enable.auto.commit=false
kafka.group.id=StreamingPreProcessJob_test
kafka.odl.topic=sync_deepeye_bd_event_face_5029_r1p1,refresh_pre_bd_event_face_5029_r1p1,sync_standard_bd_event_face_5029_r1p1
kafka.dwd.topic=dwd_bigdata_event_face_5029_test

save.db.enable=true
